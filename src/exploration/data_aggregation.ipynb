{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Data Files based on category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.abspath(os.getcwd())\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
    "crimes_outcomes_stopnsearch_dir = os.path.join(DATA_DIR, 'curated_crimes_outcomes')\n",
    "curated_data_dir = os.path.join(DATA_DIR, 'curated_data')\n",
    "\n",
    "if not os.path.exists(curated_data_dir):\n",
    "    os.makedirs(curated_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Curating all relevant CSV filenames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "61it [00:00, 5174.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Stop and Search files: 2568\n",
      "Number of Outcome files: 2561\n",
      "Number of Crime files: 2656\n",
      "\n",
      "Combining files into single DataFrame(s) based on category...\n",
      "\n",
      "Combining Crime files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2656/2656 [01:04<00:00, 41.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crime DataFrame saved as CSV file\n",
      "\n",
      "Crime DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5380493 entries, 229729 to 31907449\n",
      "Data columns (total 12 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   Crime ID               object \n",
      " 1   Month                  object \n",
      " 2   Reported by            object \n",
      " 3   Falls within           object \n",
      " 4   Longitude              float64\n",
      " 5   Latitude               float64\n",
      " 6   Location               object \n",
      " 7   LSOA code              object \n",
      " 8   LSOA name              object \n",
      " 9   Crime type             object \n",
      " 10  Last outcome category  object \n",
      " 11  Context                float64\n",
      "dtypes: float64(3), object(9)\n",
      "memory usage: 533.6+ MB\n",
      "None\n",
      "\n",
      "Combining Outcome files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2561/2561 [00:41<00:00, 61.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome DataFrame saved as CSV file\n",
      "\n",
      "Outcome DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2759652 entries, 109482 to 21661168\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   Crime ID      object \n",
      " 1   Month         object \n",
      " 2   Reported by   object \n",
      " 3   Falls within  object \n",
      " 4   Longitude     float64\n",
      " 5   Latitude      float64\n",
      " 6   Location      object \n",
      " 7   LSOA code     object \n",
      " 8   LSOA name     object \n",
      " 9   Outcome type  object \n",
      "dtypes: float64(2), object(8)\n",
      "memory usage: 231.6+ MB\n",
      "None\n",
      "CPU times: user 2min 7s, sys: 17.2 s, total: 2min 25s\n",
      "Wall time: 2min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#* ====================================================================\n",
    "#* === Data Aggregation for Course provided data ===\n",
    "#* ====================================================================\n",
    "\n",
    "stop_and_search_files, outcome_files, crime_files = [], [], []\n",
    "\n",
    "# Collect all relevant CSV filenames\n",
    "print(\"\\nCurating all relevant CSV filenames...\")\n",
    "for root, dirs, files in tqdm(os.walk(crimes_outcomes_stopnsearch_dir)):\n",
    "    for file in files:\n",
    "        if file.endswith(\"stop-and-search.csv\"):\n",
    "            stop_and_search_files.append(os.path.join(root, file))\n",
    "        elif file.endswith(\"outcomes.csv\"):\n",
    "            outcome_files.append(os.path.join(root, file))\n",
    "        elif file.endswith(\"street.csv\"):\n",
    "            crime_files.append(os.path.join(root, file))\n",
    "        else:\n",
    "            print(f\"Unknown file category: {file}\")\n",
    "\n",
    "# Print Statistics\n",
    "print(f\"\\nNumber of Stop and Search files: {len(stop_and_search_files)}\")\n",
    "print(f\"Number of Outcome files: {len(outcome_files)}\")\n",
    "print(f\"Number of Crime files: {len(crime_files)}\")\n",
    "\n",
    "# Combine all files into one DataFrame\n",
    "print(\"\\nCombining files into single DataFrame(s) based on category...\")\n",
    "\n",
    "# print(\"\\nCombining Stop and Search files...\")\n",
    "# stop_and_search_df = pd.concat((pd.read_csv(file) for file in tqdm(stop_and_search_files)), ignore_index=True)\n",
    "# stop_and_search_df.to_csv(os.path.join(curated_data_dir, 'course_stop_and_search.csv'), index=False)\n",
    "# print('Stop and Search DataFrame saved as CSV file')\n",
    "# print(\"\\nStop and Search DataFrame Info:\")\n",
    "# print(stop_and_search_df.info())\n",
    "\n",
    "# del stop_and_search_df\n",
    "\n",
    "print(\"\\nCombining Crime files...\")\n",
    "crime_df = pd.concat((pd.read_csv(file) for file in tqdm(crime_files)), ignore_index=True)\n",
    "crime_df = crime_df[crime_df['Falls within'] == 'Metropolitan Police Service']\n",
    "crime_df.to_csv(os.path.join(curated_data_dir, 'course_crime.csv'), index=False)\n",
    "print('Crime DataFrame saved as CSV file')\n",
    "print(\"\\nCrime DataFrame Info:\")\n",
    "print(crime_df.info())\n",
    "\n",
    "del crime_df\n",
    "\n",
    "print(\"\\nCombining Outcome files...\")\n",
    "outcome_df = pd.concat((pd.read_csv(file) for file in tqdm(outcome_files)), ignore_index=True)\n",
    "outcome_df = outcome_df[outcome_df['Falls within'] == 'Metropolitan Police Service']\n",
    "outcome_df.to_csv(os.path.join(curated_data_dir, 'course_outcome.csv'), index=False)\n",
    "print('Outcome DataFrame saved as CSV file')\n",
    "print(\"\\nOutcome DataFrame Info:\")\n",
    "print(outcome_df.info())\n",
    "\n",
    "del outcome_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combining Crime and Outcome files...\n"
     ]
    }
   ],
   "source": [
    "# Read the crimes and outcomes data and merge on 'Crime ID'\n",
    "print(\"\\nCombining Crime and Outcome files...\")\n",
    "crimes_df = pd.read_csv(os.path.join(curated_data_dir, 'course_crime.csv'))\n",
    "crimes_df.drop('Last outcome category', axis=1)\n",
    "outcomes_df = pd.read_csv(os.path.join(curated_data_dir, 'course_outcome.csv'))\n",
    "outcomes_df = outcomes_df[['Crime ID', 'Outcome type']]\n",
    "outcomes_df.rename(columns={'Outcome type': 'Last Outcome Category'})\n",
    "\n",
    "crimes_outcomes_df = pd.merge(crimes_df, outcomes_df, on='Crime ID', how='left')\n",
    "crimes_outcomes_df.drop_duplicates(inplace=True)\n",
    "crimes_outcomes_df = crimes_outcomes_df[~crimes_outcomes_df['Crime ID'].isnull()]\n",
    "crimes_outcomes_df = crimes_outcomes_df[~crimes_outcomes_df['Crime ID'].isna()]\n",
    "crimes_outcomes_df.to_csv(os.path.join(curated_data_dir, 'course_crimes_outcomes.csv'), index=False)\n",
    "\n",
    "print('Crimes and Outcomes DataFrame saved as CSV file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crimes_outcomes_df = pd.merge(crimes_df, outcomes_df, on='Crime ID')\n",
    "# crimes_outcomes_df.to_csv(os.path.join(curated_data_dir, 'course_crimes_outcomes.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEGACY CODE FROM HERE ON OUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #* ====================================================================\n",
    "# #* === Data Aggregation for \"London Police Data 2014-2017\" ===\n",
    "# #* ====================================================================\n",
    "\n",
    "# # Data Source: https://www.kaggle.com/datasets/sohier/london-police-records\n",
    "\n",
    "# london_police_data_dir = os.path.join(DATA_DIR, 'Kaggle_London_Police_Data_2014-2017')\n",
    "# street_crime_df = pd.read_csv(os.path.join(london_police_data_dir, 'london-street.csv'))\n",
    "\n",
    "# # Get columns from course provided data for consistency\n",
    "# # course_street_crimes = pd.read_csv(os.path.join(curated_data_dir, 'crime.csv')).columns\n",
    "# # course_outcomes = pd.read_csv(os.path.join(curated_data_dir, 'outcome.csv')).columns\n",
    "# course_street_crimes = pd.read_csv(os.path.join(curated_data_dir, 'course_crime.csv')).columns\n",
    "# course_outcomes = pd.read_csv(os.path.join(curated_data_dir, 'course_outcome.csv')).columns\n",
    "\n",
    "# kaggle_2014_2017_street_crime_df = street_crime_df[course_street_crimes]\n",
    "\n",
    "# kaggle_2014_2017_street_crime_df = street_crime_df[street_crime_df['Falls within'] == 'Metropolitan Police Service'].reset_index(drop=True)\n",
    "\n",
    "# kaggle_2014_2017_street_crime_df.to_csv(os.path.join(curated_data_dir, 'kaggle_2014_2017_crime.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #* ====================================================================\n",
    "# #* === Data Aggregation for \"UK Police Street Crime 2018-2021\" ===\n",
    "# #* ====================================================================\n",
    "\n",
    "# # Crimes Data Source: https://www.kaggle.com/datasets/tantable/all-uk-police-street-crime-102018-to-092021\n",
    "# # Outcomes Data Source(s):\n",
    "\n",
    "# # Also need to filter out data that is not from London (Metropolitan Police Service)\n",
    "# # No outcome data available for this dataset\n",
    "\n",
    "# kaggle_2018_2021 = dd.read_csv(os.path.join(DATA_DIR, \"UK_Police_Street_Crime_2018-10-01_to_2021_09_31.csv\"))\n",
    "# kaggle_2018_2021 = kaggle_2018_2021[kaggle_2018_2021['Falls within'] == 'Metropolitan Police Service'].compute()\n",
    "# kaggle_2018_2021 = kaggle_2018_2021[~kaggle_2018_2021['Crime ID'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #* ====================================================================\n",
    "# #* === Sanity Check ===\n",
    "# #* ====================================================================\n",
    "\n",
    "# # Go through each dataset, remove rows that are duplicates\n",
    "# # print the columns for each dataset and ensure they are the same \n",
    "\n",
    "# # Course Provided Data\n",
    "# course_crime = pd.read_csv(os.path.join(curated_data_dir, 'course_crime.csv'))\n",
    "\n",
    "# print(\"\\nCourse Provided Data:\")\n",
    "# print(\"Course Crime Columns:\")\n",
    "# print(course_crime.columns)\n",
    "\n",
    "# # Kaggle 2014-2017 Data\n",
    "# kaggle_2014_2017_crime = pd.read_csv(os.path.join(curated_data_dir, 'kaggle_2014_2017_crime.csv'))\n",
    "\n",
    "# print(\"\\nKaggle 2014-2017 Data:\")\n",
    "# print(\"Kaggle 2014-2017 Crime Columns:\")\n",
    "# print(kaggle_2014_2017_crime.columns)\n",
    "\n",
    "# # Kaggle 2018-2021 Data\n",
    "# kaggle_2018_2021 \n",
    "# print(\"\\nKaggle 2018-2021 Data:\")\n",
    "# print(\"Kaggle 2018-2021 Crime Columns:\")\n",
    "# print(kaggle_2018_2021.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #* ====================================================================\n",
    "# #* === Final Aggregation - combining all street crimes and outcomes ===\n",
    "# #* ====================================================================\n",
    "\n",
    "# #! NOTE: No crimes data available from July 2017 to September 2018\n",
    "\n",
    "# # minor cleaning\n",
    "# kaggle_2018_2021 = kaggle_2018_2021[['Crime ID', 'Month', 'Reported by', 'Falls within',\n",
    "#        'Longitude', 'Latitude', 'Location', 'LSOA code', 'LSOA name',\n",
    "#        'Crime type', 'Last outcome category']]\n",
    "\n",
    "# final_crimes = pd.concat([course_crime, kaggle_2014_2017_crime, kaggle_2018_2021], ignore_index=True)\n",
    "\n",
    "# # remove duplicate rows\n",
    "# final_crimes = final_crimes.drop_duplicates()\n",
    "\n",
    "# # remove columns with no crime ID\n",
    "# final_crimes = final_crimes[~final_crimes['Crime ID'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export\n",
    "# final_crimes.to_csv(os.path.join(curated_data_dir, 'final_crimes.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DC2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
