{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "%load_ext cudf.pandas\n",
    "import dask.dataframe as dd\n",
    "\n",
    "import datashader\n",
    "from datashader import transfer_functions as tf\n",
    "from datashader.colors import Hot, viridis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Data Files based on category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.abspath(os.getcwd())\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
    "crimes_outcomes_stopnsearch_dir = os.path.join(DATA_DIR, 'crimes_outcomes_stopnsearch')\n",
    "curated_data_dir = os.path.join(DATA_DIR, 'curated_data')\n",
    "\n",
    "if not os.path.exists(curated_data_dir):\n",
    "    os.makedirs(curated_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Curating all relevant CSV filenames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "37it [00:00, 1608.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Stop and Search files: 1450\n",
      "Number of Outcome files: 1510\n",
      "Number of Crime files: 1575\n",
      "\n",
      "Combining files into single DataFrame(s) based on category...\n",
      "\n",
      "Combining Stop and Search files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1450/1450 [00:15<00:00, 93.67it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop and Search DataFrame saved as CSV and Parquet files\n",
      "\n",
      "Stop and Search DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1493820 entries, 0 to 1493819\n",
      "Data columns (total 15 columns):\n",
      " #   Column                                    Non-Null Count    Dtype  \n",
      "---  ------                                    --------------    -----  \n",
      " 0   Type                                      1493820 non-null  object \n",
      " 1   Date                                      1493820 non-null  object \n",
      " 2   Part of a policing operation              922495 non-null   object \n",
      " 3   Policing operation                        0 non-null        float64\n",
      " 4   Latitude                                  1281002 non-null  float64\n",
      " 5   Longitude                                 1281002 non-null  float64\n",
      " 6   Gender                                    1430714 non-null  object \n",
      " 7   Age range                                 1291519 non-null  object \n",
      " 8   Self-defined ethnicity                    1398446 non-null  object \n",
      " 9   Officer-defined ethnicity                 1380411 non-null  object \n",
      " 10  Legislation                               1456082 non-null  object \n",
      " 11  Object of search                          1399398 non-null  object \n",
      " 12  Outcome                                   1461810 non-null  object \n",
      " 13  Outcome linked to object of search        495787 non-null   object \n",
      " 14  Removal of more than just outer clothing  738257 non-null   object \n",
      "dtypes: float64(3), object(12)\n",
      "memory usage: 171.0+ MB\n",
      "None\n",
      "\n",
      "Combining Outcome files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1510/1510 [01:18<00:00, 19.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome DataFrame saved as CSV and Parquet files\n",
      "\n",
      "Outcome DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14241608 entries, 0 to 14241607\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   Crime ID      object \n",
      " 1   Month         object \n",
      " 2   Reported by   object \n",
      " 3   Falls within  object \n",
      " 4   Longitude     float64\n",
      " 5   Latitude      float64\n",
      " 6   Location      object \n",
      " 7   LSOA code     object \n",
      " 8   LSOA name     object \n",
      " 9   Outcome type  object \n",
      "dtypes: float64(2), object(8)\n",
      "memory usage: 1.1+ GB\n",
      "None\n",
      "\n",
      "Combining Crime files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1575/1575 [01:40<00:00, 15.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crime DataFrame saved as CSV and Parquet files\n",
      "\n",
      "Crime DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18486818 entries, 0 to 18486817\n",
      "Data columns (total 12 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   Crime ID               object \n",
      " 1   Month                  object \n",
      " 2   Reported by            object \n",
      " 3   Falls within           object \n",
      " 4   Longitude              float64\n",
      " 5   Latitude               float64\n",
      " 6   Location               object \n",
      " 7   LSOA code              object \n",
      " 8   LSOA name              object \n",
      " 9   Crime type             object \n",
      " 10  Last outcome category  object \n",
      " 11  Context                float64\n",
      "dtypes: float64(3), object(9)\n",
      "memory usage: 1.7+ GB\n",
      "None\n",
      "CPU times: user 9min 47s, sys: 53 s, total: 10min 40s\n",
      "Wall time: 10min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#* ====================================================================\n",
    "#* === Data Aggregation and Curation ===\n",
    "#* ====================================================================\n",
    "\n",
    "stop_and_search_files, outcome_files, crime_files = [], [], []\n",
    "\n",
    "# Collect all relevant CSV filenames\n",
    "print(\"\\nCurating all relevant CSV filenames...\")\n",
    "for root, dirs, files in tqdm(os.walk(crimes_outcomes_stopnsearch_dir)):\n",
    "    for file in files:\n",
    "        if file.endswith(\"stop-and-search.csv\"):\n",
    "            stop_and_search_files.append(os.path.join(root, file))\n",
    "        elif file.endswith(\"outcomes.csv\"):\n",
    "            outcome_files.append(os.path.join(root, file))\n",
    "        elif file.endswith(\"street.csv\"):\n",
    "            crime_files.append(os.path.join(root, file))\n",
    "        else:\n",
    "            print(f\"Unknown file category: {file}\")\n",
    "\n",
    "# Print Statistics\n",
    "print(f\"\\nNumber of Stop and Search files: {len(stop_and_search_files)}\")\n",
    "print(f\"Number of Outcome files: {len(outcome_files)}\")\n",
    "print(f\"Number of Crime files: {len(crime_files)}\")\n",
    "\n",
    "# Combine all files into one DataFrame\n",
    "print(\"\\nCombining files into single DataFrame(s) based on category...\")\n",
    "\n",
    "print(\"\\nCombining Stop and Search files...\")\n",
    "stop_and_search_df = pd.concat((pd.read_csv(file) for file in tqdm(stop_and_search_files)), ignore_index=True)\n",
    "stop_and_search_df.to_csv(os.path.join(curated_data_dir, 'stop_and_search.csv'), index=False)\n",
    "stop_and_search_df.to_parquet(os.path.join(curated_data_dir, 'stop_and_search.parquet'), index=False)\n",
    "print('Stop and Search DataFrame saved as CSV and Parquet files')\n",
    "print(\"\\nStop and Search DataFrame Info:\")\n",
    "print(stop_and_search_df.info())\n",
    "\n",
    "del stop_and_search_df\n",
    "\n",
    "print(\"\\nCombining Outcome files...\")\n",
    "outcome_df = pd.concat((pd.read_csv(file) for file in tqdm(outcome_files)), ignore_index=True)\n",
    "outcome_df.to_csv(os.path.join(curated_data_dir, 'outcome.csv'), index=False)\n",
    "outcome_df.to_parquet(os.path.join(curated_data_dir, 'outcome.parquet'), index=False)\n",
    "print('Outcome DataFrame saved as CSV and Parquet files')\n",
    "print(\"\\nOutcome DataFrame Info:\")\n",
    "print(outcome_df.info())\n",
    "\n",
    "del outcome_df\n",
    "\n",
    "print(\"\\nCombining Crime files...\")\n",
    "crime_df = pd.concat((pd.read_csv(file) for file in tqdm(crime_files)), ignore_index=True)\n",
    "crime_df.to_csv(os.path.join(curated_data_dir, 'crime.csv'), index=False)\n",
    "crime_df.to_parquet(os.path.join(curated_data_dir, 'crime.parquet'), index=False)\n",
    "print('Crime DataFrame saved as CSV and Parquet files')\n",
    "print(\"\\nCrime DataFrame Info:\")\n",
    "print(crime_df.info())\n",
    "\n",
    "del crime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DC2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
