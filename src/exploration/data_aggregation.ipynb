{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Data Files based on category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.abspath(os.getcwd())\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
    "crimes_outcomes_stopnsearch_dir = os.path.join(DATA_DIR, 'crimes_outcomes_stopnsearch')\n",
    "curated_data_dir = os.path.join(DATA_DIR, 'curated_data')\n",
    "\n",
    "if not os.path.exists(curated_data_dir):\n",
    "    os.makedirs(curated_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#* ====================================================================\n",
    "#* === Data Aggregation for Course provided data ===\n",
    "#* ====================================================================\n",
    "\n",
    "stop_and_search_files, outcome_files, crime_files = [], [], []\n",
    "\n",
    "# Collect all relevant CSV filenames\n",
    "print(\"\\nCurating all relevant CSV filenames...\")\n",
    "for root, dirs, files in tqdm(os.walk(crimes_outcomes_stopnsearch_dir)):\n",
    "    for file in files:\n",
    "        if file.endswith(\"stop-and-search.csv\"):\n",
    "            stop_and_search_files.append(os.path.join(root, file))\n",
    "        elif file.endswith(\"outcomes.csv\"):\n",
    "            outcome_files.append(os.path.join(root, file))\n",
    "        elif file.endswith(\"street.csv\"):\n",
    "            crime_files.append(os.path.join(root, file))\n",
    "        else:\n",
    "            print(f\"Unknown file category: {file}\")\n",
    "\n",
    "# Print Statistics\n",
    "print(f\"\\nNumber of Stop and Search files: {len(stop_and_search_files)}\")\n",
    "print(f\"Number of Outcome files: {len(outcome_files)}\")\n",
    "print(f\"Number of Crime files: {len(crime_files)}\")\n",
    "\n",
    "# Combine all files into one DataFrame\n",
    "print(\"\\nCombining files into single DataFrame(s) based on category...\")\n",
    "\n",
    "print(\"\\nCombining Stop and Search files...\")\n",
    "stop_and_search_df = pd.concat((pd.read_csv(file) for file in tqdm(stop_and_search_files)), ignore_index=True)\n",
    "stop_and_search_df.to_csv(os.path.join(curated_data_dir, 'course_stop_and_search.csv'), index=False)\n",
    "print('Stop and Search DataFrame saved as CSV file')\n",
    "print(\"\\nStop and Search DataFrame Info:\")\n",
    "print(stop_and_search_df.info())\n",
    "\n",
    "del stop_and_search_df\n",
    "\n",
    "print(\"\\nCombining Crime files...\")\n",
    "crime_df = pd.concat((pd.read_csv(file) for file in tqdm(crime_files)), ignore_index=True)\n",
    "crime_df.to_csv(os.path.join(curated_data_dir, 'course_crime.csv'), index=False)\n",
    "print('Crime DataFrame saved as CSV file')\n",
    "print(\"\\nCrime DataFrame Info:\")\n",
    "print(crime_df.info())\n",
    "\n",
    "del crime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32155/3203443688.py:10: DtypeWarning: Columns (2,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  stop_search_df = pd.read_csv(os.path.join(london_police_data_dir, 'london-stop-and-search.csv'))\n"
     ]
    }
   ],
   "source": [
    "#* ====================================================================\n",
    "#* === Data Aggregation for \"London Police Data 2014-2017\" ===\n",
    "#* ====================================================================\n",
    "\n",
    "# Data Source: https://www.kaggle.com/datasets/sohier/london-police-records\n",
    "\n",
    "london_police_data_dir = os.path.join(DATA_DIR, 'Kaggle_London_Police_Data_2014-2017')\n",
    "street_crime_df = pd.read_csv(os.path.join(london_police_data_dir, 'london-street.csv'))\n",
    "\n",
    "# Get columns from course provided data for consistency\n",
    "# course_street_crimes = pd.read_csv(os.path.join(curated_data_dir, 'crime.csv')).columns\n",
    "# course_outcomes = pd.read_csv(os.path.join(curated_data_dir, 'outcome.csv')).columns\n",
    "course_street_crimes = pd.read_csv(os.path.join(curated_data_dir, 'course_crime.csv')).columns\n",
    "course_outcomes = pd.read_csv(os.path.join(curated_data_dir, 'course_outcome.csv')).columns\n",
    "\n",
    "kaggle_2014_2017_street_crime_df = street_crime_df[course_street_crimes]\n",
    "\n",
    "kaggle_2014_2017_street_crime_df = street_crime_df[street_crime_df['Falls within'] == 'Metropolitan Police Service'].reset_index(drop=True)\n",
    "\n",
    "kaggle_2014_2017_street_crime_df.to_csv(os.path.join(curated_data_dir, 'kaggle_2014_2017_crime.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* ====================================================================\n",
    "#* === Data Aggregation for \"UK Police Street Crime 2018-2021\" ===\n",
    "#* ====================================================================\n",
    "\n",
    "# Crimes Data Source: https://www.kaggle.com/datasets/tantable/all-uk-police-street-crime-102018-to-092021\n",
    "# Outcomes Data Source(s):\n",
    "\n",
    "# Also need to filter out data that is not from London (Metropolitan Police Service)\n",
    "# No outcome data available for this dataset\n",
    "\n",
    "kaggle_2018_2021 = dd.read_csv(os.path.join(DATA_DIR, \"UK_Police_Street_Crime_2018-10-01_to_2021_09_31.csv\"))\n",
    "kaggle_2018_2021 = kaggle_2018_2021[kaggle_2018_2021['Falls within'] == 'Metropolitan Police Service'].compute()\n",
    "kaggle_2018_2021 = kaggle_2018_2021[~kaggle_2018_2021['Crime ID'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Course Provided Data:\n",
      "Course Crime Columns:\n",
      "Index(['Crime ID', 'Month', 'Reported by', 'Falls within', 'Longitude',\n",
      "       'Latitude', 'Location', 'LSOA code', 'LSOA name', 'Crime type',\n",
      "       'Last outcome category', 'Context'],\n",
      "      dtype='object')\n",
      "\n",
      "Kaggle 2014-2017 Data:\n",
      "Kaggle 2014-2017 Crime Columns:\n",
      "Index(['Crime ID', 'Month', 'Reported by', 'Falls within', 'Longitude',\n",
      "       'Latitude', 'Location', 'LSOA code', 'LSOA name', 'Crime type',\n",
      "       'Last outcome category', 'Context'],\n",
      "      dtype='object')\n",
      "\n",
      "Kaggle 2018-2021 Data:\n",
      "Kaggle 2018-2021 Crime Columns:\n",
      "Index(['Unnamed: 0', 'Crime ID', 'Month', 'Reported by', 'Falls within',\n",
      "       'Longitude', 'Latitude', 'Location', 'LSOA code', 'LSOA name',\n",
      "       'Crime type', 'Last outcome category', 'Context'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#* ====================================================================\n",
    "#* === Sanity Check ===\n",
    "#* ====================================================================\n",
    "\n",
    "# Go through each dataset, remove rows that are duplicates\n",
    "# print the columns for each dataset and ensure they are the same \n",
    "\n",
    "# Course Provided Data\n",
    "course_crime = pd.read_csv(os.path.join(curated_data_dir, 'course_crime.csv'))\n",
    "\n",
    "print(\"\\nCourse Provided Data:\")\n",
    "print(\"Course Crime Columns:\")\n",
    "print(course_crime.columns)\n",
    "\n",
    "# Kaggle 2014-2017 Data\n",
    "kaggle_2014_2017_crime = pd.read_csv(os.path.join(curated_data_dir, 'kaggle_2014_2017_crime.csv'))\n",
    "\n",
    "print(\"\\nKaggle 2014-2017 Data:\")\n",
    "print(\"Kaggle 2014-2017 Crime Columns:\")\n",
    "print(kaggle_2014_2017_crime.columns)\n",
    "\n",
    "# Kaggle 2018-2021 Data\n",
    "kaggle_2018_2021 \n",
    "print(\"\\nKaggle 2018-2021 Data:\")\n",
    "print(\"Kaggle 2018-2021 Crime Columns:\")\n",
    "print(kaggle_2018_2021.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* ====================================================================\n",
    "#* === Final Aggregation - combining all street crimes and outcomes ===\n",
    "#* ====================================================================\n",
    "\n",
    "#! NOTE: No crimes data available from July 2017 to September 2018\n",
    "\n",
    "# minor cleaning\n",
    "kaggle_2018_2021 = kaggle_2018_2021[['Crime ID', 'Month', 'Reported by', 'Falls within',\n",
    "       'Longitude', 'Latitude', 'Location', 'LSOA code', 'LSOA name',\n",
    "       'Crime type', 'Last outcome category']]\n",
    "\n",
    "final_crimes = pd.concat([course_crime, kaggle_2014_2017_crime, kaggle_2018_2021], ignore_index=True)\n",
    "\n",
    "# remove duplicate rows\n",
    "final_crimes = final_crimes.drop_duplicates()\n",
    "\n",
    "# remove columns with no crime ID\n",
    "final_crimes = final_crimes[~final_crimes['Crime ID'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export\n",
    "final_crimes.to_csv(os.path.join(curated_data_dir, 'final_crimes.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DC2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
