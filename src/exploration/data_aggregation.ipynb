{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Data Files based on category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.abspath(os.getcwd())\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
    "crimes_outcomes_stopnsearch_dir = os.path.join(DATA_DIR, 'curated_crimes_outcomes')\n",
    "use_of_force_dir = os.path.join(DATA_DIR, 'use_of_force')\n",
    "curated_data_dir = os.path.join(DATA_DIR, 'curated_data')\n",
    "\n",
    "if not os.path.exists(curated_data_dir):\n",
    "    os.makedirs(curated_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Curating all relevant CSV filenames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "61it [00:00, 5174.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Stop and Search files: 2568\n",
      "Number of Outcome files: 2561\n",
      "Number of Crime files: 2656\n",
      "\n",
      "Combining files into single DataFrame(s) based on category...\n",
      "\n",
      "Combining Crime files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2656/2656 [01:04<00:00, 41.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crime DataFrame saved as CSV file\n",
      "\n",
      "Crime DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5380493 entries, 229729 to 31907449\n",
      "Data columns (total 12 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   Crime ID               object \n",
      " 1   Month                  object \n",
      " 2   Reported by            object \n",
      " 3   Falls within           object \n",
      " 4   Longitude              float64\n",
      " 5   Latitude               float64\n",
      " 6   Location               object \n",
      " 7   LSOA code              object \n",
      " 8   LSOA name              object \n",
      " 9   Crime type             object \n",
      " 10  Last outcome category  object \n",
      " 11  Context                float64\n",
      "dtypes: float64(3), object(9)\n",
      "memory usage: 533.6+ MB\n",
      "None\n",
      "\n",
      "Combining Outcome files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2561/2561 [00:41<00:00, 61.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome DataFrame saved as CSV file\n",
      "\n",
      "Outcome DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2759652 entries, 109482 to 21661168\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   Crime ID      object \n",
      " 1   Month         object \n",
      " 2   Reported by   object \n",
      " 3   Falls within  object \n",
      " 4   Longitude     float64\n",
      " 5   Latitude      float64\n",
      " 6   Location      object \n",
      " 7   LSOA code     object \n",
      " 8   LSOA name     object \n",
      " 9   Outcome type  object \n",
      "dtypes: float64(2), object(8)\n",
      "memory usage: 231.6+ MB\n",
      "None\n",
      "CPU times: user 2min 7s, sys: 17.2 s, total: 2min 25s\n",
      "Wall time: 2min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#* ====================================================================\n",
    "#* === Data Aggregation for Course provided data ===\n",
    "#* ====================================================================\n",
    "\n",
    "stop_and_search_files, outcome_files, crime_files = [], [], []\n",
    "\n",
    "# Collect all relevant CSV filenames\n",
    "print(\"\\nCurating all relevant CSV filenames...\")\n",
    "for root, dirs, files in tqdm(os.walk(crimes_outcomes_stopnsearch_dir)):\n",
    "    for file in files:\n",
    "        if file.endswith(\"stop-and-search.csv\"):\n",
    "            stop_and_search_files.append(os.path.join(root, file))\n",
    "        elif file.endswith(\"outcomes.csv\"):\n",
    "            outcome_files.append(os.path.join(root, file))\n",
    "        elif file.endswith(\"street.csv\"):\n",
    "            crime_files.append(os.path.join(root, file))\n",
    "        else:\n",
    "            print(f\"Unknown file category: {file}\")\n",
    "\n",
    "# Print Statistics\n",
    "print(f\"\\nNumber of Stop and Search files: {len(stop_and_search_files)}\")\n",
    "print(f\"Number of Outcome files: {len(outcome_files)}\")\n",
    "print(f\"Number of Crime files: {len(crime_files)}\")\n",
    "\n",
    "# Combine all files into one DataFrame\n",
    "print(\"\\nCombining files into single DataFrame(s) based on category...\")\n",
    "\n",
    "# print(\"\\nCombining Stop and Search files...\")\n",
    "# stop_and_search_df = pd.concat((pd.read_csv(file) for file in tqdm(stop_and_search_files)), ignore_index=True)\n",
    "# stop_and_search_df.to_csv(os.path.join(curated_data_dir, 'course_stop_and_search.csv'), index=False)\n",
    "# print('Stop and Search DataFrame saved as CSV file')\n",
    "# print(\"\\nStop and Search DataFrame Info:\")\n",
    "# print(stop_and_search_df.info())\n",
    "\n",
    "# del stop_and_search_df\n",
    "\n",
    "print(\"\\nCombining Crime files...\")\n",
    "crime_df = pd.concat((pd.read_csv(file) for file in tqdm(crime_files)), ignore_index=True)\n",
    "crime_df = crime_df[crime_df['Falls within'] == 'Metropolitan Police Service']\n",
    "crime_df.to_csv(os.path.join(curated_data_dir, 'course_crime.csv'), index=False)\n",
    "print('Crime DataFrame saved as CSV file')\n",
    "print(\"\\nCrime DataFrame Info:\")\n",
    "print(crime_df.info())\n",
    "\n",
    "del crime_df\n",
    "\n",
    "print(\"\\nCombining Outcome files...\")\n",
    "outcome_df = pd.concat((pd.read_csv(file) for file in tqdm(outcome_files)), ignore_index=True)\n",
    "outcome_df = outcome_df[outcome_df['Falls within'] == 'Metropolitan Police Service']\n",
    "outcome_df.to_csv(os.path.join(curated_data_dir, 'course_outcome.csv'), index=False)\n",
    "print('Outcome DataFrame saved as CSV file')\n",
    "print(\"\\nOutcome DataFrame Info:\")\n",
    "print(outcome_df.info())\n",
    "\n",
    "del outcome_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combining Crime and Outcome files...\n"
     ]
    }
   ],
   "source": [
    "# Read the crimes and outcomes data and merge on 'Crime ID'\n",
    "print(\"\\nCombining Crime and Outcome files...\")\n",
    "crimes_df = pd.read_csv(os.path.join(curated_data_dir, 'course_crime.csv'))\n",
    "crimes_df.drop('Last outcome category', axis=1)\n",
    "outcomes_df = pd.read_csv(os.path.join(curated_data_dir, 'course_outcome.csv'))\n",
    "outcomes_df = outcomes_df[['Crime ID', 'Outcome type']]\n",
    "outcomes_df.rename(columns={'Outcome type': 'Last Outcome Category'})\n",
    "\n",
    "crimes_outcomes_df = pd.merge(crimes_df, outcomes_df, on='Crime ID', how='left')\n",
    "crimes_outcomes_df.drop_duplicates(inplace=True)\n",
    "crimes_outcomes_df = crimes_outcomes_df[~crimes_outcomes_df['Crime ID'].isnull()]\n",
    "crimes_outcomes_df = crimes_outcomes_df[~crimes_outcomes_df['Crime ID'].isna()]\n",
    "crimes_outcomes_df.to_csv(os.path.join(curated_data_dir, 'course_crimes_outcomes.csv'), index=False)\n",
    "\n",
    "print('Crimes and Outcomes DataFrame saved as CSV file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crimes_outcomes_df = pd.merge(crimes_df, outcomes_df, on='Crime ID')\n",
    "# crimes_outcomes_df.to_csv(os.path.join(curated_data_dir, 'course_crimes_outcomes.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Use of Force Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_columns = [\n",
    "    \"IncidentDate\", \"IncidentTime\", \"Incident Location: Street/Highway\", \"Incident Location: Public Transport\", \"Incident Location: Retail Premises\", \"Incident Location: Open ground (e.g. park, car park, field)\", \"Incident Location: Licensed Premises\", \"Incident Location: Sports or Event Stadia\", \"Incident Location: Hospital/A&E (non-mental-health setting)\", \"Incident Location: Mental Health Setting\", \"Incident Location: Police vehicle with prisoner handling cage\", \"Incident Location: Police vehicle without prisoner handling cage\", \"Incident Location: Dwelling\", \"Incident Location: Police station (excluding custody block)\", \"Incident Location: Custody Block\", \"Incident Location: Ambulance\", \"Incident Location: Other\", \"Borough\", \"PrimaryConduct\", \"AssaultedBySubject\", \"ThreatenedWithWeapon\", \"AssaultedWithWeapon\", \"Impact Factor: Possesion of a weapon\", \"Impact Factor: Alcohol\", \"Impact Factor: Drugs\", \"Impact Factor: Mental Health\", \"Impact Factor: Prior Knowledge\", \"Impact Factor: Size/Gender/Build\", \"Impact Factor: Acute Behavioural Disorder\", \"Impact Factor: Crowd\", \"Impact Factor: Other\", \"Reason for Force: Protect self\", \"Reason for Force: Protect Public\", \"Reason for Force: Protect Subject\", \"Reason for Force: Protect Other Officers\", \"Reason for Force: Prevent Offence\", \"Reason for Force: Secure Evidence\", \"Reason for Force: Effect Search\", \"Reason for Force: Effect Arrest\", \"Reason for Force: Method of Entry\", \"Reason for Force: Remove Handcuffs\", \"Reason for Force: Prevent Harm\", \"Reason for Force: Prevent Escape\", \"Reason for Force: Other\", \"MainDuty\", \"Firearms Aimed\", \"Firearms Fired\", \"SubjectAge\", \"SubjectGender\", \"SubjectEthnicity\", \"PhysicalDisability\", \"MentalDisability\", \"StaffInjured\", \"StaffInjuryIntentional\", \"StaffInjuryLevel\", \"StaffMedProvided\", \"SubjectInjured\", \"SubjectMedOffered\", \"SubjectMedProvided\", \"Outcome: Made off/escaped\", \"Outcome: Arrested\", \"Outcome: Hospitalised\", \"Outcome: Detained - Mental Health Act\", \"Outcome: Fatality\", \"Outcome: Other\", \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]/tmp/ipykernel_14119/920000125.py:7: DtypeWarning: Columns (60,61,62,63,64,65,66,67,68,69,70,71,72,73,136,176,216) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(use_of_force_dir, file))\n",
      " 33%|███▎      | 1/3 [00:01<00:02,  1.30s/it]/tmp/ipykernel_14119/920000125.py:7: DtypeWarning: Columns (60,61,62,63,64,65,66,67,68,69,70,71,136,176,216) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(use_of_force_dir, file))\n",
      " 67%|██████▋   | 2/3 [00:03<00:01,  1.76s/it]/tmp/ipykernel_14119/920000125.py:7: DtypeWarning: Columns (60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,98,138,178,218) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(use_of_force_dir, file))\n",
      "100%|██████████| 3/3 [00:06<00:00,  2.05s/it]\n"
     ]
    }
   ],
   "source": [
    "# go through each of the use of force files, and append the relevant columns to a single dataframe\n",
    "use_of_force_files = os.listdir(use_of_force_dir)\n",
    "\n",
    "use_of_force_df = pd.DataFrame(columns=useful_columns)\n",
    "\n",
    "for file in tqdm(use_of_force_files):\n",
    "    df = pd.read_csv(os.path.join(use_of_force_dir, file))\n",
    "    df = df[useful_columns]\n",
    "    use_of_force_df = pd.concat([use_of_force_df, df], ignore_index=True)\n",
    "\n",
    "use_of_force_df.to_csv(os.path.join(curated_data_dir, 'curated_use_of_force.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEGACY CODE FROM HERE ON OUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #* ====================================================================\n",
    "# #* === Data Aggregation for \"London Police Data 2014-2017\" ===\n",
    "# #* ====================================================================\n",
    "\n",
    "# # Data Source: https://www.kaggle.com/datasets/sohier/london-police-records\n",
    "\n",
    "# london_police_data_dir = os.path.join(DATA_DIR, 'Kaggle_London_Police_Data_2014-2017')\n",
    "# street_crime_df = pd.read_csv(os.path.join(london_police_data_dir, 'london-street.csv'))\n",
    "\n",
    "# # Get columns from course provided data for consistency\n",
    "# # course_street_crimes = pd.read_csv(os.path.join(curated_data_dir, 'crime.csv')).columns\n",
    "# # course_outcomes = pd.read_csv(os.path.join(curated_data_dir, 'outcome.csv')).columns\n",
    "# course_street_crimes = pd.read_csv(os.path.join(curated_data_dir, 'course_crime.csv')).columns\n",
    "# course_outcomes = pd.read_csv(os.path.join(curated_data_dir, 'course_outcome.csv')).columns\n",
    "\n",
    "# kaggle_2014_2017_street_crime_df = street_crime_df[course_street_crimes]\n",
    "\n",
    "# kaggle_2014_2017_street_crime_df = street_crime_df[street_crime_df['Falls within'] == 'Metropolitan Police Service'].reset_index(drop=True)\n",
    "\n",
    "# kaggle_2014_2017_street_crime_df.to_csv(os.path.join(curated_data_dir, 'kaggle_2014_2017_crime.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #* ====================================================================\n",
    "# #* === Data Aggregation for \"UK Police Street Crime 2018-2021\" ===\n",
    "# #* ====================================================================\n",
    "\n",
    "# # Crimes Data Source: https://www.kaggle.com/datasets/tantable/all-uk-police-street-crime-102018-to-092021\n",
    "# # Outcomes Data Source(s):\n",
    "\n",
    "# # Also need to filter out data that is not from London (Metropolitan Police Service)\n",
    "# # No outcome data available for this dataset\n",
    "\n",
    "# kaggle_2018_2021 = dd.read_csv(os.path.join(DATA_DIR, \"UK_Police_Street_Crime_2018-10-01_to_2021_09_31.csv\"))\n",
    "# kaggle_2018_2021 = kaggle_2018_2021[kaggle_2018_2021['Falls within'] == 'Metropolitan Police Service'].compute()\n",
    "# kaggle_2018_2021 = kaggle_2018_2021[~kaggle_2018_2021['Crime ID'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #* ====================================================================\n",
    "# #* === Sanity Check ===\n",
    "# #* ====================================================================\n",
    "\n",
    "# # Go through each dataset, remove rows that are duplicates\n",
    "# # print the columns for each dataset and ensure they are the same \n",
    "\n",
    "# # Course Provided Data\n",
    "# course_crime = pd.read_csv(os.path.join(curated_data_dir, 'course_crime.csv'))\n",
    "\n",
    "# print(\"\\nCourse Provided Data:\")\n",
    "# print(\"Course Crime Columns:\")\n",
    "# print(course_crime.columns)\n",
    "\n",
    "# # Kaggle 2014-2017 Data\n",
    "# kaggle_2014_2017_crime = pd.read_csv(os.path.join(curated_data_dir, 'kaggle_2014_2017_crime.csv'))\n",
    "\n",
    "# print(\"\\nKaggle 2014-2017 Data:\")\n",
    "# print(\"Kaggle 2014-2017 Crime Columns:\")\n",
    "# print(kaggle_2014_2017_crime.columns)\n",
    "\n",
    "# # Kaggle 2018-2021 Data\n",
    "# kaggle_2018_2021 \n",
    "# print(\"\\nKaggle 2018-2021 Data:\")\n",
    "# print(\"Kaggle 2018-2021 Crime Columns:\")\n",
    "# print(kaggle_2018_2021.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #* ====================================================================\n",
    "# #* === Final Aggregation - combining all street crimes and outcomes ===\n",
    "# #* ====================================================================\n",
    "\n",
    "# #! NOTE: No crimes data available from July 2017 to September 2018\n",
    "\n",
    "# # minor cleaning\n",
    "# kaggle_2018_2021 = kaggle_2018_2021[['Crime ID', 'Month', 'Reported by', 'Falls within',\n",
    "#        'Longitude', 'Latitude', 'Location', 'LSOA code', 'LSOA name',\n",
    "#        'Crime type', 'Last outcome category']]\n",
    "\n",
    "# final_crimes = pd.concat([course_crime, kaggle_2014_2017_crime, kaggle_2018_2021], ignore_index=True)\n",
    "\n",
    "# # remove duplicate rows\n",
    "# final_crimes = final_crimes.drop_duplicates()\n",
    "\n",
    "# # remove columns with no crime ID\n",
    "# final_crimes = final_crimes[~final_crimes['Crime ID'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export\n",
    "# final_crimes.to_csv(os.path.join(curated_data_dir, 'final_crimes.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DC2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
